{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import sys, pprint\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Data\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add new column called labeld to split data into toxic and non toxic\n",
    "#If Labeled column is 0, this means that the comment is not toxic at all\n",
    "x=df['toxic']+df['severe_toxic']+df['obscene']+df['threat']+df['insult']+df['identity_hate']\n",
    "df['labeled']=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               159571\n",
       "comment_text     159571\n",
       "toxic             15294\n",
       "severe_toxic       1595\n",
       "obscene            8449\n",
       "threat              478\n",
       "insult             7877\n",
       "identity_hate      1405\n",
       "labeled           16225\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how non zeros rows are there for each columns\n",
    "df.astype(bool).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    s = s.replace('\"',\"\")\n",
    "    s = s.replace(',',\"\")\n",
    "    s = s.replace('.',\"\")\n",
    "    s = s.replace('.',\"\")\n",
    "    s = s.replace(\"?\",\"\")\n",
    "    s = s.replace(\"!\",\"\")\n",
    "    s = s.replace(\"[\",\"\")\n",
    "    s = s.replace(\"]\",\"\")\n",
    "    s = s.replace(\"{\",\"\")\n",
    "    s = s.replace(\"}\",\"\")\n",
    "    s = s.replace(\"(\",\"\")\n",
    "    s = s.replace(\")\",\"\")\n",
    "    s = s.replace(\":\",\"\")\n",
    "    s = s.replace(\";\",\"\")\n",
    "    s=s.replace(\"\\n\",\" \") \n",
    "    s=s.replace(\"\\r\",\" \") \n",
    "    s = re.sub(r'[0-9]', \"\", s)\n",
    "    s = re.sub(r'!?.,;:*&$%@#^&', \"\", s)\n",
    "    s = s.replace('-',\"\")\n",
    "    s = s.replace('_',\"\")\n",
    "    s = s.replace('+',\"\")\n",
    "    s = s.replace('>',\"\")\n",
    "    s = s.replace('<',\"\")\n",
    "    s = s.replace('=',\"\")\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"what's\", \"what is \", s)\n",
    "    s = re.sub(r\"\\'s\", \" \", s)\n",
    "    s = re.sub(r\"\\'ve\", \" have \", s)\n",
    "    s = re.sub(r\"can't\", \"cannot \", s)\n",
    "    s = re.sub(r\"n't\", \" not \", s)\n",
    "    s = re.sub(r\"i'm\", \"i am \", s)\n",
    "    s = re.sub(r\"\\'re\", \" are \", s)\n",
    "    s = re.sub(r\"\\'d\", \" would \", s)\n",
    "    s = re.sub(r\"\\'ll\", \" will \", s)\n",
    "    s = re.sub(r\"\\'scuse\", \" excuse \", s)\n",
    "    s = re.sub('\\W', ' ', s)\n",
    "    s = re.sub('\\s+', ' ', s)\n",
    "    s = s.replace(\"\\\\\",\"\")\n",
    "    s = s.replace(\"/\",\"\")\n",
    "    s = s.replace(\"Ù€\",\"\")\n",
    "    return s\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=len(df[\"comment_text\"])\n",
    "#for i in range(1, l):\n",
    "    #df[\"comment_text\"][i]=remove_punctuation(str(df[\"comment_text\"][i]))\n",
    "len(df[\"comment_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create two data frames, one that has only toxic comments\n",
    "#And another one that has only non toxic comments\n",
    "toxic=df[df.labeled != 0]\n",
    "nontoxic=df[df.labeled == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16225"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For testing you can check numer of toxic or no toxic comments by changing the toxic to nontoxic and runing the code below\n",
    "toxic.astype(bool).sum(axis=0)\n",
    "len(toxic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nontoxic1=nontoxic[1:16226]\n",
    "nontoxic2=nontoxic[16226:32451]\n",
    "nontoxic3=nontoxic[32451:48676]\n",
    "nontoxic4=nontoxic[48676:64901]\n",
    "nontoxic5=nontoxic[64901:81126]\n",
    "nontoxic6=nontoxic[81126:97351]\n",
    "nontoxic7=nontoxic[97351:113576]\n",
    "nontoxic8=nontoxic[113576:129801]\n",
    "nontoxic9=nontoxic[127121:143346]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This code is to create one data frame that has coments which are toxic and non-toxic\n",
    "frame1 = [toxic, nontoxic1]\n",
    "frame2 = [toxic, nontoxic2]\n",
    "frame3 = [toxic, nontoxic3]\n",
    "frame4 = [toxic, nontoxic4]\n",
    "frame5 = [toxic, nontoxic5]\n",
    "frame6 = [toxic, nontoxic6]\n",
    "frame7 = [toxic, nontoxic7]\n",
    "frame8 = [toxic, nontoxic8]\n",
    "frame9 = [toxic, nontoxic9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This code is to create one data frame that has coments which are toxic and non-toxic\n",
    "result1 = pd.concat(frame1)\n",
    "result2 = pd.concat(frame2)\n",
    "result3 = pd.concat(frame3)\n",
    "result4 = pd.concat(frame4)\n",
    "result5 = pd.concat(frame5)\n",
    "result6 = pd.concat(frame6)\n",
    "result7 = pd.concat(frame7)\n",
    "result8 = pd.concat(frame8)\n",
    "result9 = pd.concat(frame9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result1 = result1.sample(frac=1).reset_index(drop=True)\n",
    "result1.to_csv(\"train1.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "result2 = result2.sample(frac=1).reset_index(drop=True)\n",
    "result2.to_csv(\"train2.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "result3 = result3.sample(frac=1).reset_index(drop=True)\n",
    "result3.to_csv(\"train3.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "result4 = result4.sample(frac=1).reset_index(drop=True)\n",
    "result4.to_csv(\"train4.csv\", encoding=\"utf-8\",index=False)\n",
    "\n",
    "result5 = result5.sample(frac=1).reset_index(drop=True)\n",
    "result5.to_csv(\"train5.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "result6 = result6.sample(frac=1).reset_index(drop=True)\n",
    "result6.to_csv(\"train6.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "result7 = result7.sample(frac=1).reset_index(drop=True)\n",
    "result7.to_csv(\"train7.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "result8 = result8.sample(frac=1).reset_index(drop=True)\n",
    "result8.to_csv(\"train8.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "result9 = result9.sample(frac=1).reset_index(drop=True)\n",
    "result9.to_csv(\"train9.csv\", encoding=\"utf-8\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32450"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train1.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "l=len(df)\n",
    "for i in range(1, l):\n",
    "    df[\"comment_text\"][i]=remove_punctuation(str(df[\"comment_text\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"train1_cleaned.csv\", encoding=\"utf-8\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Ayah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\Ayah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Ayah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Ayah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Ayah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Ayah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Ayah\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train2.csv')\n",
    "l=len(df)\n",
    "for i in range(1, l):\n",
    "    df[\"comment_text\"][i]=remove_punctuation(str(df[\"comment_text\"][i]))\n",
    "df.to_csv(\"train2_cleaned.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "df = pd.read_csv('train3.csv')\n",
    "l=len(df)\n",
    "for i in range(1, l):\n",
    "    df[\"comment_text\"][i]=remove_punctuation(str(df[\"comment_text\"][i]))\n",
    "df.to_csv(\"train3_cleaned.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "df = pd.read_csv('train4.csv')\n",
    "l=len(df)\n",
    "for i in range(1, l):\n",
    "    df[\"comment_text\"][i]=remove_punctuation(str(df[\"comment_text\"][i]))\n",
    "df.to_csv(\"train4_cleaned.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "df = pd.read_csv('train5.csv')\n",
    "l=len(df)\n",
    "for i in range(1, l):\n",
    "    df[\"comment_text\"][i]=remove_punctuation(str(df[\"comment_text\"][i]))\n",
    "df.to_csv(\"train5_cleaned.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "df = pd.read_csv('train6.csv')\n",
    "l=len(df)\n",
    "for i in range(1, l):\n",
    "    df[\"comment_text\"][i]=remove_punctuation(str(df[\"comment_text\"][i]))\n",
    "df.to_csv(\"train6_cleaned.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "df = pd.read_csv('train7.csv')\n",
    "l=len(df)\n",
    "for i in range(1, l):\n",
    "    df[\"comment_text\"][i]=remove_punctuation(str(df[\"comment_text\"][i]))\n",
    "df.to_csv(\"train7_cleaned.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "df = pd.read_csv('train8.csv')\n",
    "l=len(df)\n",
    "for i in range(1, l):\n",
    "    df[\"comment_text\"][i]=remove_punctuation(str(df[\"comment_text\"][i]))\n",
    "df.to_csv(\"train8_cleaned.csv\", encoding=\"utf-8\",index=False) \n",
    "\n",
    "df = pd.read_csv('train9.csv')\n",
    "l=len(df)\n",
    "for i in range(1, l):\n",
    "    df[\"comment_text\"][i]=remove_punctuation(str(df[\"comment_text\"][i]))\n",
    "df.to_csv(\"train9_cleaned.csv\", encoding=\"utf-8\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('test.csv')\n",
    "l=len(df)\n",
    "for i in range(1, l):\n",
    "    df[\"comment_text\"][i]=remove_punctuation(str(df[\"comment_text\"][i]))\n",
    "df.to_csv(\"test_cleaned.csv\", encoding=\"utf-8\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout=open(\"big_train.csv\",\"a\", encoding=\"utf8\")\n",
    "# first file:\n",
    "for line in open(\"train1_cleaned.csv\", encoding=\"utf8\"):\n",
    "    fout.write(line)\n",
    "# now the rest: \n",
    "for i in range(2,10):\n",
    "    k=0;\n",
    "    f = open(\"train\"+str(i)+\"_cleaned.csv\", encoding=\"utf8\")\n",
    "    for line in f:\n",
    "        if k==0:\n",
    "            k=1\n",
    "            continue\n",
    "        fout.write(line)\n",
    "    f.close() # not really needed\n",
    "fout.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
