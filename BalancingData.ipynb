{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import csv\n",
    "import sys, pprint\n",
    "from sqlalchemy import create_engine # database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Add new column called labeld to split data into toxic and non toxic\n",
    "#If Labeled column is 0, this means that the comment is not toxic at all\n",
    "\n",
    "x=df['toxic']+df['severe_toxic']+df['obscene']+df['threat']+df['insult']+df['identity_hate']\n",
    "df['labeled']=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               159571\n",
       "comment_text     159571\n",
       "toxic             15294\n",
       "severe_toxic       1595\n",
       "obscene            8449\n",
       "threat              478\n",
       "insult             7877\n",
       "identity_hate      1405\n",
       "labeled           16225\n",
       "dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check how non zeros rows are there for each columns\n",
    "df.astype(bool).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143346"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of comments that are non toxic\n",
    "159571-16225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127121"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of comments to delete\n",
    "143346-16225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1131876717871444"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Percentage of toxic to nontoxic is\n",
    "16225/143346"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create two data frames, one that has only toxic comments\n",
    "#And another one that has only non toxic comments\n",
    "\n",
    "toxic=df[df.labeled != 0]\n",
    "nontoxic=df[df.labeled == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               16225\n",
       "comment_text     16225\n",
       "toxic                0\n",
       "severe_toxic         0\n",
       "obscene              0\n",
       "threat               0\n",
       "insult               0\n",
       "identity_hate        0\n",
       "labeled              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For testing you can check numer of toxic or no toxic comments by changing the toxic to nontoxic and runing the code below\n",
    "nontoxic4.astype(bool).sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample number 1 of non-toxic comments, this sample has only 16225 rows\n",
    "nontoxic1=nontoxic.drop(nontoxic.index[1:127121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample number 2 of non-toxic comments, this sample has only 16225 rows\n",
    "nontoxic2=nontoxic.drop(nontoxic.index[1000:128121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample number 3 of non-toxic comments, this sample has only 16225 rows\n",
    "nontoxic3=nontoxic.drop(nontoxic.index[2000:129121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample number 4 of non-toxic comments, this sample has only 16225 rows\n",
    "nontoxic4=nontoxic.drop(nontoxic.index[12000:139121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sample number 5 of non-toxic comments, this sample has only 16225 rows\n",
    "nontoxic5=nontoxic.drop(nontoxic.index[16225:143346])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is to create one data frame that has coments which are toxic and non-toxic\n",
    "frame1 = [toxic, nontoxic1]\n",
    "frame2 = [toxic, nontoxic2]\n",
    "frame3 = [toxic, nontoxic3]\n",
    "frame4 = [toxic, nontoxic4]\n",
    "frame5 = [toxic, nontoxic5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This code is to create one data frame that has coments which are toxic and non-toxic\n",
    "result1 = pd.concat(frame1)\n",
    "result2 = pd.concat(frame2)\n",
    "result3 = pd.concat(frame3)\n",
    "result4 = pd.concat(frame4)\n",
    "result5 = pd.concat(frame5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is shuffle comments (toxic and non-toxic) \n",
    "#Then save data frame to CSV. We have 5 files that has different non-toxic comments\n",
    "result1 = result1.sample(frac=1).reset_index(drop=True)\n",
    "result1.to_csv(\"train1.csv\", encoding=\"utf-8\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = result2.sample(frac=1).reset_index(drop=True)\n",
    "result2.to_csv(\"train2.csv\", encoding=\"utf-8\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = result3.sample(frac=1).reset_index(drop=True)\n",
    "result3.to_csv(\"train3.csv\", encoding=\"utf-8\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4 = result4.sample(frac=1).reset_index(drop=True)\n",
    "result4.to_csv(\"train4.csv\", encoding=\"utf-8\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result5 = result5.sample(frac=1).reset_index(drop=True)\n",
    "result5.to_csv(\"train5.csv\", encoding=\"utf-8\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
