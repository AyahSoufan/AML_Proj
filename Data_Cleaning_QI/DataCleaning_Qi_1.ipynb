{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\warmp\\\\Documents\\\\pythonlearning\\\\AML'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       gay antisemmitian archangel white tiger meow g...\n",
       "1                    pair jew-hating weiner nazi schmucks\n",
       "2       think fagget get oife burn hell hate 'm sorry ...\n",
       "3       kill niggers hard others say include racists s...\n",
       "4       u r tw@ fuck u gay boyu r smellyfuck ur mum po...\n",
       "5       gay existence cdvf proof sad twat also ugly wi...\n",
       "6       dictionaries dare call contribution spam kurd ...\n",
       "7       gay motherfucker know livei go sand face offth...\n",
       "8       studid cock sucker u stop callin ok frank garr...\n",
       "9       first time bitch fuck i'll find live sodomize ...\n",
       "10      fuck faggot care get block long everyone know ...\n",
       "11      hey freak hermaphrodite please unprotect user ...\n",
       "12                                     ghe fag learn know\n",
       "13                                 shut fat poop kick ass\n",
       "14                               good edit polar bear gay\n",
       "15      demonte morton u bastard stop deletin' shit u ...\n",
       "16                             bla bla blasuck irishguy =\n",
       "17      evidence present tone evidence reject go ficti...\n",
       "18                                        faggot get life\n",
       "19           i'm glad wikipedia bias fill retard children\n",
       "20      fuck gay wad fuck mum oh wait gay dont mom hah...\n",
       "21      aaron swartz stop fuck revert goddamn edit thi...\n",
       "22      gay homo hope choke penis die send big bleck g...\n",
       "23                        racist goddamn neo-nazi big boy\n",
       "24      fascit nazi socialist bastard filthy hippy dar...\n",
       "25      usernhrhs homo like mitt romney usernhrhs homo...\n",
       "26      fuck nazi propaganda odpierdalcie sie jebani f...\n",
       "27      im sorry fuck stupid nice person give warn fuc...\n",
       "28      actually fully arabic islamic correct spell un...\n",
       "29      pedophiles sex criminals imperial japan nazi g...\n",
       "                              ...                        \n",
       "2789    remove copy-paste separate article case know t...\n",
       "2790    i've get almost chart problem can't find music...\n",
       "2791                                           talk fiend\n",
       "2792    still academic gain direktor would love see di...\n",
       "2793    satisfy mention talk page i'm work update map ...\n",
       "2794    dont think hinduism take position hinduism com...\n",
       "2795    speedy deletion dustin garringer tag place dus...\n",
       "2796    asperger's syndrome edit history discussion pa...\n",
       "2797    regard reference cite thank head reason change...\n",
       "2798                                   cheeseburger fatty\n",
       "2799    excoriate characteragain sarek probably intera...\n",
       "2800    vandal https//enwikipediaorg/wiki/user_talkbla...\n",
       "2801    revert back december version keep simple defin...\n",
       "2802    probably want include thing make section menti...\n",
       "2803    spore video game consensus check archive page ...\n",
       "2804    can't see arabesque spell even use arabesk dis...\n",
       "2805                                         i've request\n",
       "2806    edit tasksdays account ip address ip address r...\n",
       "2807    please notice keepeng track document things ca...\n",
       "2808    mention synthesis article user human educate w...\n",
       "2809    wikipediawikiproject succession box standardiz...\n",
       "2810    incest laws purely motivate eugenic principles...\n",
       "2811                      dumb offend users mother fucker\n",
       "2812    disagree policy proper venue discuss policy pa...\n",
       "2813    response comment lingeron think agree disagree...\n",
       "2814    block account block please contribute primary ...\n",
       "2815               prefer keep racial homophobic material\n",
       "2816    hang minute scobey i'm irish i'd like confirm ...\n",
       "2817    ultimatum maybe admins try support one side di...\n",
       "2818    block result long peronsal vendetta bya user t...\n",
       "Name: comment_text, Length: 2819, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_hate1 = pd.read_csv(r'C:\\Users\\warmp\\Documents\\pythonlearning\\AML\\balanced_dataset\\balanced_dataset\\identity_hate1.csv')\n",
    "identity_hate1['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       gay antisemmitian archangel white tiger meow g...\n",
       "1                    pair jew hating weiner nazi schmucks\n",
       "2       think fagget get oife burn hell hate 'm sorry ...\n",
       "3       kill niggers hard others say include racists s...\n",
       "4       u r tw  fuck u gay boyu r smellyfuck ur mum po...\n",
       "5       gay existence cdvf proof sad twat also ugly wi...\n",
       "6       dictionaries dare call contribution spam kurd ...\n",
       "7       gay motherfucker know livei go sand face offth...\n",
       "8       studid cock sucker u stop callin ok frank garr...\n",
       "9       first time bitch fuck i'll find live sodomize ...\n",
       "10      fuck faggot care get block long everyone know ...\n",
       "11      hey freak hermaphrodite please unprotect user ...\n",
       "12                                     ghe fag learn know\n",
       "13                                 shut fat poop kick ass\n",
       "14                               good edit polar bear gay\n",
       "15      demonte morton u bastard stop deletin' shit u ...\n",
       "16                             bla bla blasuck irishguy  \n",
       "17      evidence present tone evidence reject go ficti...\n",
       "18                                        faggot get life\n",
       "19           i'm glad wikipedia bias fill retard children\n",
       "20      fuck gay wad fuck mum oh wait gay dont mom hah...\n",
       "21      aaron swartz stop fuck revert goddamn edit thi...\n",
       "22      gay homo hope choke penis die send big bleck g...\n",
       "23                        racist goddamn neo nazi big boy\n",
       "24      fascit nazi socialist bastard filthy hippy dar...\n",
       "25      usernhrhs homo like mitt romney usernhrhs homo...\n",
       "26      fuck nazi propaganda odpierdalcie sie jebani f...\n",
       "27      im sorry fuck stupid nice person give warn fuc...\n",
       "28      actually fully arabic islamic correct spell un...\n",
       "29      pedophiles sex criminals imperial japan nazi g...\n",
       "                              ...                        \n",
       "2789    remove copy paste separate article case know t...\n",
       "2790    i've get almost chart problem can't find music...\n",
       "2791                                           talk fiend\n",
       "2792    still academic gain direktor would love see di...\n",
       "2793    satisfy mention talk page i'm work update map ...\n",
       "2794    dont think hinduism take position hinduism com...\n",
       "2795    speedy deletion dustin garringer tag place dus...\n",
       "2796    asperger's syndrome edit history discussion pa...\n",
       "2797    regard reference cite thank head reason change...\n",
       "2798                                   cheeseburger fatty\n",
       "2799    excoriate characteragain sarek probably intera...\n",
       "2800    vandal https  enwikipediaorg wiki user talkbla...\n",
       "2801    revert back december version keep simple defin...\n",
       "2802    probably want include thing make section menti...\n",
       "2803    spore video game consensus check archive page ...\n",
       "2804    can't see arabesque spell even use arabesk dis...\n",
       "2805                                         i've request\n",
       "2806    edit tasksdays account ip address ip address r...\n",
       "2807    please notice keepeng track document things ca...\n",
       "2808    mention synthesis article user human educate w...\n",
       "2809    wikipediawikiproject succession box standardiz...\n",
       "2810    incest laws purely motivate eugenic principles...\n",
       "2811                      dumb offend users mother fucker\n",
       "2812    disagree policy proper venue discuss policy pa...\n",
       "2813    response comment lingeron think agree disagree...\n",
       "2814    block account block please contribute primary ...\n",
       "2815               prefer keep racial homophobic material\n",
       "2816    hang minute scobey i'm irish i'd like confirm ...\n",
       "2817    ultimatum maybe admins try support one side di...\n",
       "2818    block result long peronsal vendetta bya user t...\n",
       "Name: comment_text, Length: 2819, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"@\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"/\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"=\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"-\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"±\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"*\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"+\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"-\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"#\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"€\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"Ã\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"©\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"Â\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"$\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"Ù\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"#\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"Ø\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"§\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"%\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"¶\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"?\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"&\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"_\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"â\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"Ž\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"¢\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"Ý\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"£\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"»\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"œ\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"¬\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"Ð\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"Ç\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"~\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"™\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"·\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"†\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"ˆ\",\" \")\n",
    "identity_hate1['comment_text'] = identity_hate1['comment_text'].str.replace(\"Î\",\" \")                                            \n",
    "identity_hate1['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identity_hate1.to_csv('identity_hate1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
