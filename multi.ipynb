{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('big_train.csv')\n",
    "test_df = pd.read_csv('test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_target = ['obscene','insult','toxic','severe_toxic','identity_hate','threat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check missing values in numeric columns\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the character length for the rows in the training data and record these\n",
    "#train_df['char_length'] = train_df['comment_text'].apply(lambda x: len(str(x)))\n",
    "# look at the histogram plot for text length\n",
    "#sns.set()\n",
    "#data = train_df[cols_target]\n",
    "#test_df['char_length'] = test_df['comment_text'].apply(lambda x: len(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean the comment_text in train_df\n",
    "cleaned_train_comment = []\n",
    "for i in range(0,len(train_df)):\n",
    "   # cleaned_comment = clean_text(train_df['comment_text'][i])\n",
    "    cleaned_train_comment.append(train_df['comment_text'][i])\n",
    "train_df['comment_text'] = pd.Series(cleaned_train_comment).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean the comment_text in test_df\n",
    "cleaned_test_comment = []\n",
    "for i in range(0,len(test_df)):\n",
    "   # cleaned_comment = clean_text(test_df['comment_text'][i])\n",
    "    cleaned_test_comment.append(train_df['comment_text'][i])\n",
    "test_df['comment_text'] = pd.Series(cleaned_test_comment).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_df = train_df.drop('char_length',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292050,) (153164,)\n"
     ]
    }
   ],
   "source": [
    "X = train_df.comment_text\n",
    "test_X = test_df.comment_text\n",
    "print(X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import and instantiate TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(max_features=20000,stop_words='english')\n",
    "vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<292050x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4724591 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# learn the vocabulary in the training data, then use it to create a document-term matrix\n",
    "X_dtm = vect.fit_transform(X)\n",
    "# examine the document-term matrix created from X_train\n",
    "X_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<153164x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2476128 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform the test data using the earlier fitted vocabulary, into a document-term matrix\n",
    "test_X_dtm = vect.transform(test_X)\n",
    "# examine the document-term matrix from X_test\n",
    "test_X_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing obscene\n",
      "Training accuracy is 0.9340318438623524\n",
      "... Processing insult\n",
      "Training accuracy is 0.8995103578154425\n",
      "... Processing toxic\n",
      "Training accuracy is 0.9136414997431946\n",
      "... Processing severe_toxic\n",
      "Training accuracy is 0.9618763910289334\n",
      "... Processing identity_hate\n",
      "Training accuracy is 0.9729429892141757\n",
      "... Processing threat\n",
      "Training accuracy is 0.991241225817497\n"
     ]
    }
   ],
   "source": [
    "# import and instantiate the Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "logreg = LogisticRegression(C=1.0)\n",
    "\n",
    "# create submission file\n",
    "submission_binary = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "for label in cols_target:\n",
    "    print('... Processing {}'.format(label))\n",
    "    y = train_df[label]\n",
    "    # train the model using X_dtm & y\n",
    "    logreg.fit(X_dtm, y)\n",
    "    # compute the training accuracy\n",
    "    y_pred_X = logreg.predict(X_dtm)\n",
    "    print('Training accuracy is {}'.format(accuracy_score(y, y_pred_X)))\n",
    "    # compute the predicted probabilities for X_test_dtm\n",
    "    test_y_prob = logreg.predict_proba(test_X_dtm)[:,1]\n",
    "    submission_binary[label] = test_y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_binary.head()\n",
    "# generate submission file\n",
    "submission_binary.to_csv('submission_binary.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create submission file\n",
    "submission_chains = pd.read_csv('sample_submission.csv')\n",
    "# create a function to add features\n",
    "def add_feature(X, feature_to_add):\n",
    "    '''\n",
    "    Returns sparse feature matrix with added feature.\n",
    "    feature_to_add can also be a list of features.\n",
    "    '''\n",
    "    from scipy.sparse import csr_matrix, hstack\n",
    "    return hstack([X, csr_matrix(feature_to_add).T], 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing obscene\n",
      "Training Accuracy is 0.9429857901044342\n",
      "Shape of X_dtm is now (292050, 5001)\n",
      "Shape of test_X_dtm is now (153164, 5001)\n",
      "... Processing insult\n",
      "Training Accuracy is 0.9288751926040062\n",
      "Shape of X_dtm is now (292050, 5002)\n",
      "Shape of test_X_dtm is now (153164, 5002)\n",
      "... Processing toxic\n",
      "Training Accuracy is 0.9192021914055812\n",
      "Shape of X_dtm is now (292050, 5003)\n",
      "Shape of test_X_dtm is now (153164, 5003)\n",
      "... Processing severe_toxic\n",
      "Training Accuracy is 0.9764252696456086\n",
      "Shape of X_dtm is now (292050, 5004)\n",
      "Shape of test_X_dtm is now (153164, 5004)\n",
      "... Processing identity_hate\n",
      "Training Accuracy is 0.9897003937681904\n",
      "Shape of X_dtm is now (292050, 5005)\n",
      "Shape of test_X_dtm is now (153164, 5005)\n",
      "... Processing threat\n",
      "Training Accuracy is 0.9977880499914398\n",
      "Shape of X_dtm is now (292050, 5006)\n",
      "Shape of test_X_dtm is now (153164, 5006)\n"
     ]
    }
   ],
   "source": [
    "for label in cols_target:\n",
    "    print('... Processing {}'.format(label))\n",
    "    y = train_df[label]\n",
    "    # train the model using X_dtm & y\n",
    "    logreg.fit(X_dtm,y)\n",
    "    # compute the training accuracy\n",
    "    y_pred_X = logreg.predict(X_dtm)\n",
    "    print('Training Accuracy is {}'.format(accuracy_score(y,y_pred_X)))\n",
    "    # make predictions from test_X\n",
    "    test_y = logreg.predict(test_X_dtm)\n",
    "    test_y_prob = logreg.predict_proba(test_X_dtm)[:,1]\n",
    "    submission_chains[label] = test_y_prob\n",
    "    # chain current label to X_dtm\n",
    "    X_dtm = add_feature(X_dtm, y)\n",
    "    print('Shape of X_dtm is now {}'.format(X_dtm.shape))\n",
    "    # chain current label predictions to test_X_dtm\n",
    "    test_X_dtm = add_feature(test_X_dtm, test_y)\n",
    "    print('Shape of test_X_dtm is now {}'.format(test_X_dtm.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate submission file\n",
    "submission_chains.to_csv('submission_chains.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create submission file\n",
    "submission_combined = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# corr_targets = ['obscene','insult','toxic']\n",
    "for label in cols_target:\n",
    "    submission_combined[label] = 0.5*(submission_chains[label]+submission_binary[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999348</td>\n",
       "      <td>0.174231</td>\n",
       "      <td>0.997642</td>\n",
       "      <td>0.058520</td>\n",
       "      <td>0.775079</td>\n",
       "      <td>0.585482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.007267</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.012521</td>\n",
       "      <td>0.002102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.056599</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.039543</td>\n",
       "      <td>0.006745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.009609</td>\n",
       "      <td>0.012903</td>\n",
       "      <td>0.017130</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.015270</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.245206</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.010774</td>\n",
       "      <td>0.001696</td>\n",
       "      <td>0.015898</td>\n",
       "      <td>0.000716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.999348      0.174231  0.997642  0.058520  0.775079   \n",
       "1  0000247867823ef7  0.007267      0.000725  0.002726  0.000912  0.012521   \n",
       "2  00013b17ad220c46  0.056599      0.000240  0.011013  0.000134  0.039543   \n",
       "3  00017563c3f7919a  0.009609      0.012903  0.017130  0.000644  0.015270   \n",
       "4  00017695ad8997eb  0.245206      0.001235  0.010774  0.001696  0.015898   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.585482  \n",
       "1       0.002102  \n",
       "2       0.006745  \n",
       "3       0.000121  \n",
       "4       0.000716  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate submission file\n",
    "submission_combined.to_csv('submission_combined.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
