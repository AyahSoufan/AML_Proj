{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load Data\n",
    "df = pd.read_csv('train1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Before Cleaning Add Features\n",
    "\n",
    "#Comment Lrngth\n",
    "df['total_length'] = df['comment_text'].apply(len)\n",
    "#Capitals\n",
    "df['capitals'] = df['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "#Percentages of Capitals\n",
    "df['caps_vs_length'] = df.apply(lambda row: float(row['capitals'])/float(row['total_length']),\n",
    "                                axis=1)\n",
    "#Exclamatons\n",
    "df['num_exclamation_marks'] = df['comment_text'].apply(lambda comment: comment.count('!'))\n",
    "#Questions marks\n",
    "df['num_question_marks'] = df['comment_text'].apply(lambda comment: comment.count('?'))\n",
    "#Punctuation\n",
    "df['num_punctuation'] = df['comment_text'].apply(\n",
    "    lambda comment: sum(comment.count(w) for w in '.,;:'))\n",
    "#Symbols\n",
    "df['num_symbols'] = df['comment_text'].apply(\n",
    "    lambda comment: sum(comment.count(w) for w in '*&$%'))\n",
    "#Number of words\n",
    "df['num_words'] = df['comment_text'].apply(lambda comment: len(comment.split()))\n",
    "#Number of unique words\n",
    "df['num_unique_words'] = df['comment_text'].apply(\n",
    "    lambda comment: len(set(w for w in comment.split())))\n",
    "#percentage of unique words\n",
    "df['words_vs_unique'] = df['num_unique_words'] / df['num_words']\n",
    "#Number of smiles\n",
    "df['num_smilies'] = df['comment_text'].apply(\n",
    "    lambda comment: sum(comment.count(w) for w in (':-)', ':)', ';-)', ';)')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>labeled</th>\n",
       "      <th>total_length</th>\n",
       "      <th>capitals</th>\n",
       "      <th>caps_vs_length</th>\n",
       "      <th>num_exclamation_marks</th>\n",
       "      <th>num_question_marks</th>\n",
       "      <th>num_punctuation</th>\n",
       "      <th>num_symbols</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>words_vs_unique</th>\n",
       "      <th>num_smilies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aad7994cb36e5185</td>\n",
       "      <td>Hate All Of You're Work</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cc805ab7f7edf1ef</td>\n",
       "      <td>OH NOES TEH IP BAND FROM EDITING? =[</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>26</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29bc5b83eba03c92</td>\n",
       "      <td>Wha's a reliable source mike? Something that c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c7600d185651455f</td>\n",
       "      <td>Blocked for marking link rot????????????? \\r\\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>269</td>\n",
       "      <td>6</td>\n",
       "      <td>0.022305</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dfce7de3667da10e</td>\n",
       "      <td>\"I like what you've asked.  Why do we see our ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>884</td>\n",
       "      <td>18</td>\n",
       "      <td>0.020362</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>106</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  aad7994cb36e5185                            Hate All Of You're Work      1   \n",
       "1  cc805ab7f7edf1ef               OH NOES TEH IP BAND FROM EDITING? =[      0   \n",
       "2  29bc5b83eba03c92  Wha's a reliable source mike? Something that c...      1   \n",
       "3  c7600d185651455f  Blocked for marking link rot????????????? \\r\\n...      1   \n",
       "4  dfce7de3667da10e  \"I like what you've asked.  Why do we see our ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  labeled  \\\n",
       "0             0        0       0       0              0        1   \n",
       "1             0        0       0       0              0        0   \n",
       "2             1        1       0       1              0        4   \n",
       "3             0        0       0       0              0        1   \n",
       "4             0        0       0       0              0        0   \n",
       "\n",
       "   total_length  capitals  caps_vs_length  num_exclamation_marks  \\\n",
       "0            23         5        0.217391                      0   \n",
       "1            36        26        0.722222                      0   \n",
       "2           112         3        0.026786                      0   \n",
       "3           269         6        0.022305                      0   \n",
       "4           884        18        0.020362                      0   \n",
       "\n",
       "   num_question_marks  num_punctuation  num_symbols  num_words  \\\n",
       "0                   0                0            0          5   \n",
       "1                   1                0            0          8   \n",
       "2                   2                1            0         19   \n",
       "3                  19                6            0         43   \n",
       "4                   5               10            0        140   \n",
       "\n",
       "   num_unique_words  words_vs_unique  num_smilies  \n",
       "0                 5         1.000000            0  \n",
       "1                 8         1.000000            0  \n",
       "2                19         1.000000            0  \n",
       "3                35         0.813953            0  \n",
       "4               106         0.757143            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  Hate All Of You're Work\n",
       "1                     OH NOES TEH IP BAND FROM EDITING? =[\n",
       "2        Wha's a reliable source mike? Something that c...\n",
       "3        Blocked for marking link rot?????????????     ...\n",
       "4        \"I like what you've asked.  Why do we see our ...\n",
       "5        Rather than someone explain everything they ha...\n",
       "6        SHUT UP, FAG     LOL YOU WILL BAN ME HUH?  OOH...\n",
       "7        \", 21 June 2013 (UTC)  Okay ima gey, god hate ...\n",
       "8        March 2009 (UTC)      SVR for late 2009     I ...\n",
       "9        Hey     What is the deal? How about you show s...\n",
       "10       My friend you dont know the half of it, i was ...\n",
       "11       what happened, is the protocol of the Zionist,...\n",
       "12       \":::::: Here's a quote from the textbook \"\"Uni...\n",
       "13       Hey, Azerbaboon, I dont know how to speak your...\n",
       "14       The one about TPain commenting about RayJ's se...\n",
       "15       Moron.     Says Demo Dick right there. http://...\n",
       "16       Dont you have to go through some bureaucratic ...\n",
       "17          Hi Tarc, Good points.  How long is your penis?\n",
       "18       References?     Could someone more familiar wi...\n",
       "19       \"  Then again, why waste DRV's time when it ca...\n",
       "20                                I too am a gay pedophile\n",
       "21       \"     I have no intention of making an unblock...\n",
       "22       . Also please note that I am a wanker and have...\n",
       "23       Health care is rationed in the United States. ...\n",
       "24                         You are very gay     You're gay\n",
       "25       OK, I have just put another edit on the articl...\n",
       "26       I'll try. Any chance anybody over there wants ...\n",
       "27       Oh, and there's a real irony in you mentioning...\n",
       "28       , 8 July 2006 (UTC)    Indeed, one may even as...\n",
       "29                                  Calm yo dirty ass down\n",
       "                               ...                        \n",
       "32421    , mainly borne out of that region's complicate...\n",
       "32422    Consider myself lucky??? Oh get your head out ...\n",
       "32423    Edit request from 174.3.185.61, 28 June 2010  ...\n",
       "32424    Urgent help Gina philips fansite link     Hi t...\n",
       "32425    UPDATE: I did some research and found this vid...\n",
       "32426    Suck a dick you little cunt     then go and ta...\n",
       "32427    Fuck you     PENIS    PENIS    PENIS    JACKO ...\n",
       "32428    Hello friends, Hank Chapot from California her...\n",
       "32429    Elbing disambig     Any objections to redirect...\n",
       "32430    We have featured articles about individual Pok...\n",
       "32431    When Asian is considered a race in the United ...\n",
       "32432                mezo mezo and king turtle are bastard\n",
       "32433                         Die Whore     Die you whore.\n",
       "32434    \", 17 July 2006 (UTC)    Someone above said, \"...\n",
       "32435    Go hang yoursef lazy fu...      Go hang yourse...\n",
       "32436                          i ilke giant dick in my ass\n",
       "32437    \"    I dont care about the name but there is a...\n",
       "32438    \": The first sentence is a description of a Ca...\n",
       "32439    Wikipedia is not a travell guide, and that kin...\n",
       "32440    o feel sorry for you, fuck off you american ba...\n",
       "32441    Update: I have amended the links in the articl...\n",
       "32442    I know you know I didn't make that attack. But...\n",
       "32443    \"  As I recall that was exactly what I suggest...\n",
       "32444    \"     Ryanpostlethwaite     I'm not going to s...\n",
       "32445    YOU CAN HELP CHIAN PIGS FOR LONG TIME ,BUT Y N...\n",
       "32446               Idiot is  what idiot does  202.92.40.8\n",
       "32447    Hay Hay    I love Rihanna songs disturbia and ...\n",
       "32448    You sad cocksucker..stop editing my article ot...\n",
       "32449    EDIT: Very well, you may consider this my resi...\n",
       "32450    Russia  Careful there. US currently isn't a pa...\n",
       "Name: comment_text, Length: 32451, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CLEANING:\n",
    "    # Remove \\n\n",
    "df[\"comment_text\"] = df[\"comment_text\"].str.replace(\"\\n\",\" \") \n",
    "df[\"comment_text\"] = df[\"comment_text\"].str.replace(\"\\r\",\" \")   \n",
    "    # Dealing with capitalization \n",
    "#TAKUYA\n",
    "df[\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Remove special characters\n",
    "    Qi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Remove Punctuation \n",
    "    TAKUYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Remove numbers\n",
    "    TAKUYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # Remove stopword \n",
    "    TAKUYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #Strip white space – Eliminate extra white spaces.\n",
    "    qi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANNOTATION\n",
    "    # it may include structural markup and part-of-speech tagging HTML\n",
    "    #Fay\n",
    "from bs4 import BeautifulSoup \n",
    "def ANNOTATION(df):\n",
    "    length=df.shape[0]\n",
    "    for i in range(length):\n",
    "        soup = BeautifulSoup(df.loc[i,['comment_text']].values[0],\"lxml\")\n",
    "        [s.extract() for s in soup('script','iframe','html')] \n",
    "        df.loc[i,['comment_text']]=soup.get_text()\n",
    "    return df\n",
    "\n",
    "DF=ANNOTATION(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  Hate All Of You're Work\n",
       "1                     OH NOES TEH IP BAND FROM EDITING? =[\n",
       "2        Wha's a reliable source mike? Something that c...\n",
       "3        Blocked for marking link rot????????????? \\r \\...\n",
       "4        \"I like what you've asked.  Why do we see our ...\n",
       "5        Rather than someone explain everything they ha...\n",
       "6        SHUT UP, FAG \\r \\r LOL YOU WILL BAN ME HUH?\\r ...\n",
       "7        \", 21 June 2013 (UTC)\\r Okay ima gey, god hate...\n",
       "8        March 2009 (UTC) \\r \\r  SVR for late 2009 \\r \\...\n",
       "9        Hey \\r \\r What is the deal? How about you show...\n",
       "10       My friend you dont know the half of it, i was ...\n",
       "11       what happened, is the protocol of the Zionist,...\n",
       "12       \":::::: Here's a quote from the textbook \"\"Uni...\n",
       "13       Hey, Azerbaboon, I dont know how to speak your...\n",
       "14       The one about TPain commenting about RayJ's se...\n",
       "15       Moron. \\r \\r Says Demo Dick right there. http:...\n",
       "16       Dont you have to go through some bureaucratic ...\n",
       "17          Hi Tarc, Good points.  How long is your penis?\n",
       "18       References? \\r \\r Could someone more familiar ...\n",
       "19       \"\\r Then again, why waste DRV's time when it c...\n",
       "20                                I too am a gay pedophile\n",
       "21       \"\\r \\r  I have no intention of making an unblo...\n",
       "22       . Also please note that I am a wanker and have...\n",
       "23       Health care is rationed in the United States. ...\n",
       "24                       You are very gay \\r \\r You're gay\n",
       "25       OK, I have just put another edit on the articl...\n",
       "26       I'll try. Any chance anybody over there wants ...\n",
       "27       Oh, and there's a real irony in you mentioning...\n",
       "28       , 8 July 2006 (UTC)\\r \\r Indeed, one may even ...\n",
       "29                                  Calm yo dirty ass down\n",
       "                               ...                        \n",
       "32421    , mainly borne out of that region's complicate...\n",
       "32422    Consider myself lucky??? Oh get your head out ...\n",
       "32423    Edit request from 174.3.185.61, 28 June 2010 \\...\n",
       "32424    Urgent help Gina philips fansite link \\r \\r Hi...\n",
       "32425    UPDATE: I did some research and found this vid...\n",
       "32426    Suck a dick you little cunt \\r \\r then go and ...\n",
       "32427    Fuck you \\r \\r PENIS\\r \\r PENIS\\r \\r PENIS\\r \\...\n",
       "32428    Hello friends, Hank Chapot from California her...\n",
       "32429    Elbing disambig \\r \\r Any objections to redire...\n",
       "32430    We have featured articles about individual Pok...\n",
       "32431    When Asian is considered a race in the United ...\n",
       "32432                mezo mezo and king turtle are bastard\n",
       "32433                       Die Whore \\r \\r Die you whore.\n",
       "32434    \", 17 July 2006 (UTC)\\r \\r Someone above said,...\n",
       "32435    Go hang yoursef lazy fu... \\r \\r  Go hang your...\n",
       "32436                          i ilke giant dick in my ass\n",
       "32437    \"\\r \\r I dont care about the name but there is...\n",
       "32438    \": The first sentence is a description of a Ca...\n",
       "32439    Wikipedia is not a travell guide, and that kin...\n",
       "32440    o feel sorry for you, fuck off you american ba...\n",
       "32441    Update: I have amended the links in the articl...\n",
       "32442    I know you know I didn't make that attack. But...\n",
       "32443    \"\\r As I recall that was exactly what I sugges...\n",
       "32444    \"\\r \\r  Ryanpostlethwaite \\r \\r I'm not going ...\n",
       "32445    YOU CAN HELP CHIAN PIGS FOR LONG TIME ,BUT Y N...\n",
       "32446              Idiot is  what idiot does\\r 202.92.40.8\n",
       "32447    Hay Hay\\r \\r I love Rihanna songs disturbia an...\n",
       "32448    You sad cocksucker..stop editing my article ot...\n",
       "32449    EDIT: Very well, you may consider this my resi...\n",
       "32450    Russia\\r Careful there. US currently isn't a p...\n",
       "Name: comment_text, Length: 32451, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baba\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup('<script>a</script>baba<script>b</script><h1>','lxml')\n",
    "[s.extract() for s in soup('script')]\n",
    "print(soup.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <div class=\"foo\">\n",
      "   cat dog sheep goat\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup, Comment\n",
    "data = \"\"\"<div class=\"foo\">\n",
    "cat dog sheep goat\n",
    "<!--\n",
    "<p>test</p>\n",
    "-->\n",
    "</div>\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(data,\"lxml\")\n",
    "\n",
    "for element in soup(text=lambda text: isinstance(text, Comment)):\n",
    "    element.extract()\n",
    "\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#NORMALIZATION\n",
    "    # translation (mapping) of terms in the scheme \n",
    "    Ayah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # linguistic reductions through:\n",
    "        #Stemming\n",
    "    TAKUYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lemmazation \n",
    "    TAKUYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " #Sparse terms ??\n",
    "        #We are often not interested in infrequent terms in our documents. Such “sparse” terms should be \n",
    "        #removed from the document term matrix.\n",
    "        Ayah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Word Embedding/Text Vectors\n",
    "tak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save_To_Excel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
