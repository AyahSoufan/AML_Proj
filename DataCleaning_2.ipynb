{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd   \n",
    "from nltk import tokenize\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import stem\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\" More I can't make any real suggestions on im...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation Why the edits made under my userna...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \" More I can't make any real suggestions on im...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"comment_text\"] = df_train[\"comment_text\"].str.replace(\"\\n\",\" \") #\\n removal\n",
    "df_test[\"comment_text\"] = df_test[\"comment_text\"].str.replace(\"\\n\",\" \")\n",
    "df_train[\"comment_text\"] = df_train[\"comment_text\"].str.replace(\"\\r\",\" \") #\\n removal\n",
    "df_test[\"comment_text\"] = df_test[\"comment_text\"].str.replace(\"\\r\",\" \")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC ==    The title is fine as it is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\"    == Sources ==    * Zawe Ashton on Lapland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC ==    The title is fine as it is, ...\n",
       "2  00013b17ad220c46  \"    == Sources ==    * Zawe Ashton on Lapland...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n"
     ]
    }
   ],
   "source": [
    "s = df_train[\"comment_text\"][0]\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation why the edits made under my username hardcore metallica fan were reverted? they weren't vandalisms, just closure on some gas after i voted at new york dolls fac. and please don't remove the template from the talk page since i'm retired now.89.205.38.27\n"
     ]
    }
   ],
   "source": [
    "# Captal to lower\n",
    "s = s.lower()\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation why the edits made under my username hardcore metallica fan were reverted? they weren't vandalisms, just closure on some gas after i voted at new york dolls fac. and please don't remove the template from the talk page since i'm retired now....\n"
     ]
    }
   ],
   "source": [
    "#Number removal\n",
    "def remove_number(s):\n",
    "    s = re.sub(r'[0-9]', \"\", s)\n",
    "    return s\n",
    "s = remove_number(s)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation why the edits made under my username hardcore metallica fan were reverted they werent vandalisms just closure on some gas after i voted at new york dolls fac and please dont remove the template from the talk page since im retired now\n"
     ]
    }
   ],
   "source": [
    "#Punctuation removal\n",
    "def remove_punctuation(s):\n",
    "    s = s.replace('\"',\"\")\n",
    "    s = s.replace('“',\"\")\n",
    "    s = s.replace(\"'\",\"\")\n",
    "    s = s.replace(',',\"\")\n",
    "    s = s.replace('.',\"\")\n",
    "    s = s.replace(\"?\",\"\")\n",
    "    s = s.replace(\"!\",\"\")\n",
    "    s = s.replace(\"[\",\"\")\n",
    "    s = s.replace(\"]\",\"\")\n",
    "    s = s.replace(\"{\",\"\")\n",
    "    s = s.replace(\"}\",\"\")\n",
    "    s = s.replace(\"(\",\"\")\n",
    "    s = s.replace(\")\",\"\")\n",
    "    s = s.replace(\":\",\"\")\n",
    "    s = s.replace(\";\",\"\")\n",
    "    s = s.replace(\"–\",\"\")\n",
    "    return s\n",
    "s = remove_punctuation(s)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation why the edits made under my username hardcore metallica fan were reverted they werent vandalisms just closure on some gas after i voted at new york dolls fac and please dont remove the template from the talk page since im retired now\n"
     ]
    }
   ],
   "source": [
    "def replace_contraction(s):\n",
    "    s = s.replace(\"i'm\",\"i am\")\n",
    "    s = s.replace(\"she's\",\"she is\")\n",
    "    #s = s.replace(\" ur \",\"you are\")\n",
    "    s = s.replace(\"don't\",\"do not\")\n",
    "    s = s.replace(\"aren't\",\"are not\")\n",
    "    s = s.replace(\"can't\", \"cannot\")\n",
    "    s = s.replace(\"can't've\", \"cannot have\")\n",
    "    s = s.replace(\"'cause\", \"because\")\n",
    "    s = s.replace(\"could've\", \"could have\")\n",
    "    s = s.replace(\"couldn't\", \"could not\")\n",
    "    s = s.replace(\"couldn't've\", \"could not have\")\n",
    "    s = s.replace(\"didn't\", \"did not\")\n",
    "    s = s.replace(\"doesn't\", \"does not\")\n",
    "    s = s.replace(\"don't\", \"do not\")\n",
    "    s = s.replace(\"hadn't\", \"had not\")\n",
    "    s = s.replace(\"hadn't've\", \"had not have\")\n",
    "    s = s.replace(\"hasn't\", \"has not\")\n",
    "    s = s.replace(\"haven't\", \"have not\")\n",
    "    s = s.replace(\"he'd\", \"he had\")\n",
    "    s = s.replace(\"he'd've\", \"he would have\")\n",
    "    s = s.replace(\"he'll\", \"he will\")\n",
    "    s = s.replace(\"he'll've\", \"he will have\")\n",
    "    s = s.replace(\"he's\", \"he is\")\n",
    "    s = s.replace(\"how'd\", \"how did\")\n",
    "    s = s.replace(\"how'd'y\", \"how do you\")\n",
    "    s = s.replace(\"how'll\", \"how will\")\n",
    "    s = s.replace(\"how's\", \"how is\")\n",
    "    s = s.replace(\"I'd\", \"I would\")\n",
    "    s = s.replace(\"I'd've\", \"I would have\")\n",
    "    s = s.replace(\"I'll\", \"I will\")\n",
    "    s = s.replace(\"I'll've\", \"I will have\")\n",
    "    s = s.replace(\"I'm\", \"I am\")\n",
    "    s = s.replace(\"I've\", \"I have\")\n",
    "    s = s.replace(\"isn't\", \"is not\")\n",
    "    s = s.replace(\"it'd\", \"it would\")\n",
    "    s = s.replace(\"it'd've\", \"it would have\")\n",
    "    s = s.replace(\"it'll\", \" it will\")\n",
    "    s = s.replace(\"it'll've\", \"it shall have / it will have\")\n",
    "    s = s.replace(\"it's\", \"it is\")\n",
    "    s = s.replace(\"let's\", \"let us\")\n",
    "    s = s.replace(\"ma'am\", \"madam\")\n",
    "    s = s.replace(\"mayn't\", \"may not\")\n",
    "    s = s.replace(\"might've\", \"might have\")\n",
    "    s = s.replace(\"mightn't\", \"might not\")\n",
    "    s = s.replace(\"mightn't've\", \"might not have\")\n",
    "    s = s.replace(\"must've\", \"must have\")\n",
    "    s = s.replace(\"mustn't\", \"must not\")\n",
    "    s = s.replace(\"mustn't've\", \"must not have\")\n",
    "    s = s.replace(\"needn't\", \"need not\")\n",
    "    s = s.replace(\"needn't've\", \"need not have\")\n",
    "    s = s.replace(\"o'clock\", \"of the clock\")\n",
    "    s = s.replace(\"oughtn't\", \"ought not\")\n",
    "    s = s.replace(\"oughtn't've\", \"ought not have\")\n",
    "    s = s.replace(\"shan't\", \"shall not\")\n",
    "    s = s.replace(\"sha'n't\", \"shall not\")\n",
    "    s = s.replace(\"shan't've\", \"shall not have\")\n",
    "    s = s.replace(\"she'd\", \"she would\")\n",
    "    s = s.replace(\"she'd've\", \"she would have\")\n",
    "    s = s.replace(\"she'll\", \"she will\")\n",
    "    s = s.replace(\"she'll've\", \"she shall have / she will have\")\n",
    "    s = s.replace(\"she's\", \"she is\")\n",
    "    s = s.replace(\"should've\", \"should have\")\n",
    "    s = s.replace(\"shouldn't\", \"should not\")\n",
    "    s = s.replace(\"shouldn't've\", \"should not have\")\n",
    "    s = s.replace(\"so've\", \"so have\")\n",
    "    s = s.replace(\"so's\", \"so as\")\n",
    "    s = s.replace(\"that'd\", \"that would\")\n",
    "    s = s.replace(\"that'd've\", \"that would have\")\n",
    "    s = s.replace(\"that's\", \"that is\")\n",
    "    s = s.replace(\"there'd\", \"there would\")\n",
    "    s = s.replace(\"there'd've\", \"there would have\")\n",
    "    s = s.replace(\"there's\", \"there is\")\n",
    "    s = s.replace(\"they'd\", \"they would\")\n",
    "    s = s.replace(\"they'd've\", \"they would have\")\n",
    "    s = s.replace(\"they'll\", \"tthey will\")\n",
    "    s = s.replace(\"they'll've\", \"they shall have / they will have\")\n",
    "    s = s.replace(\"they're\", \"they are\")\n",
    "    s = s.replace(\"they've\", \"they have\")\n",
    "    s = s.replace(\"to've\", \"to have\")\n",
    "    s = s.replace(\"wasn't\", \"was not\")\n",
    "    s = s.replace(\"we'd\", \"we had / we would\")\n",
    "    s = s.replace(\"we'd've\", \"we would have\")\n",
    "    s = s.replace(\"we'll\", \"we will\")\n",
    "    s = s.replace(\"we'll've\", \"we will have\")\n",
    "    s = s.replace(\"we're\", \"we are\")\n",
    "    s = s.replace(\"we've\", \"we have\")\n",
    "    s = s.replace(\"weren't\", \"were not\")\n",
    "    s = s.replace(\"what'll\", \"what shall / what will\")\n",
    "    s = s.replace(\"what'll've\", \"what shall have / what will have\")\n",
    "    s = s.replace(\"what're\", \"what are\")\n",
    "    s = s.replace(\"what's\", \"what has / what is\")\n",
    "    s = s.replace(\"what've\", \"what have\")\n",
    "    s = s.replace(\"when's\", \"when has / when is\")\n",
    "    s = s.replace(\"when've\", \"when have\")\n",
    "    s = s.replace(\"where'd\", \"where did\")\n",
    "    s = s.replace(\"where's\", \"where has / where is\")\n",
    "    s = s.replace(\"where've\", \"where have\")\n",
    "    s = s.replace(\"who'll\", \"who shall / who will\")\n",
    "    s = s.replace(\"who'll've\", \"who shall have / who will have\")\n",
    "    s = s.replace(\"who's\", \"who has / who is\")\n",
    "    s = s.replace(\"who've\", \"who have\")\n",
    "    s = s.replace(\"why's\", \"why has / why is\")\n",
    "    s = s.replace(\"why've\", \"why have\")\n",
    "    s = s.replace(\"will've\", \"will have\")\n",
    "    s = s.replace(\"won't\", \"will not\")\n",
    "    s = s.replace(\"won't've\", \"will not have\")\n",
    "    s = s.replace(\"would've\", \"would have\")\n",
    "    s = s.replace(\"wouldn't\", \"would not\")\n",
    "    s = s.replace(\"wouldn't've\", \"would not have\")\n",
    "    s = s.replace(\"y'all\", \"you all\")\n",
    "    s = s.replace(\"y'all'd\", \"you all would\")\n",
    "    s = s.replace(\"y'all'd've\", \"you all would have\")\n",
    "    s = s.replace(\"y'all're\", \"you all are\")\n",
    "    s = s.replace(\"y'all've\", \"you all have\")\n",
    "    s = s.replace(\"you'd\", \"you had / you would\")\n",
    "    s = s.replace(\"you'd've\", \"you would have\")\n",
    "    s = s.replace(\"you'll\", \"you shall / you will\")\n",
    "    s = s.replace(\"you'll've\", \"you shall have / you will have\")\n",
    "    s = s.replace(\"you're\", \"you are\")\n",
    "    s = s.replace(\"you've\", \"you have\")\n",
    "    s = s.replace(\"f**k\", \"fuck\")\n",
    "    return s\n",
    "s = replace_contraction(s)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation why the edits made under my username hardcore metallica fan were reverted they werent vandalisms just closure on some gas after i voted at new york dolls fac and please dont remove the template from the talk page since im retired now'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_symbols(s):\n",
    "    s = s.replace(\"|\",\" \")\n",
    "    s = s.replace(\"@\",\" \")\n",
    "    s = s.replace(\"/\",\" \")\n",
    "    s = s.replace('\\ ',\" \")\n",
    "    s = s.replace('\\\\ ',\" \")\n",
    "    s = s.replace(\"=\",\" \")\n",
    "    s = s.replace(\"-\",\" \")\n",
    "    s = s.replace(\"±\",\" \")\n",
    "    s = s.replace(\"~\",\" \")\n",
    "    s = s.replace(\"*\",\" \")\n",
    "    s = s.replace(\"+\",\" \")\n",
    "    s = s.replace(\"-\",\" \")\n",
    "    s = s.replace(\"#\",\" \")\n",
    "    s = s.replace(\"€\",\" \")\n",
    "    s = s.replace(\"که\",\" \")\n",
    "    s = s.replace(\"Ã\",\" \")\n",
    "    s = s.replace(\"©\",\" \")\n",
    "    s = s.replace(\"Â\",\" \")\n",
    "    s = s.replace(\"$\",\" \")\n",
    "    s = s.replace(\"Ù\",\" \")\n",
    "    s = s.replace(\"#\",\" \")\n",
    "    s = s.replace(\"Ø\",\" \")\n",
    "    s = s.replace(\"§\",\" \")\n",
    "    s = s.replace(\"%\",\" \")\n",
    "    s = s.replace(\"¶\",\" \")\n",
    "    s = s.replace(\"?\",\" \")\n",
    "    s = s.replace(\"&\",\" \")\n",
    "    s = s.replace(\"_\",\" \")\n",
    "    s = s.replace(\"â\",\" \")\n",
    "    s = s.replace(\"Ž\",\" \")\n",
    "    s = s.replace(\"¢\",\" \")\n",
    "    s = s.replace(\"Ý\",\" \")\n",
    "    s = s.replace(\"£\",\" \")\n",
    "    s = s.replace(\"»\",\" \")\n",
    "    s = s.replace(\"œ\",\" \")\n",
    "    s = s.replace(\"¬\",\" \")\n",
    "    s = s.replace(\"Ð\",\" \")\n",
    "    s = s.replace(\"Ç\",\" \")\n",
    "    s = s.replace(\"~\",\" \")\n",
    "    s = s.replace(\"™\",\" \")\n",
    "    s = s.replace(\"·\",\" \")\n",
    "    s = s.replace(\"†\",\" \")\n",
    "    s = s.replace(\"ˆ\",\" \")\n",
    "    s = s.replace(\"Î\",\" \")  \n",
    "    s = s.replace(\"←\",\" \")  \n",
    "    s = s.replace(\"✉\",\" \") \n",
    "    s = s.replace(\"•\",\" \") \n",
    "    s = s.replace(\"—\",\" \") \n",
    "    s = s.replace(\"◕\",\" \") \n",
    "    s = s.replace(\">\",\" \") \n",
    "    s = s.replace(\"つ\",\" \") \n",
    "    s = s.replace(\"با\",\" \") \n",
    "    s = s.replace(\"ان\",\" \") \n",
    "    s = s.replace(\"^\",\" \") \n",
    "    s = s.replace(\"بر\",\" \")\n",
    "    s = s.replace(\"اين\",\" \")\n",
    "    return s \n",
    "remove_symbols(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['explanation', 'why', 'the', 'edit', 'make', 'under', 'my', 'username', 'hardcore', 'metallica', 'fan', 'be', 'revert', 'they', 'werent', 'vandalisms', 'just', 'closure', 'on', 'some', 'gas', 'after', 'i', 'vote', 'at', 'new', 'york', 'dolls', 'fac', 'and', 'please', 'dont', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'im', 'retire', 'now']\n"
     ]
    }
   ],
   "source": [
    "#Lematization and stemming\n",
    "words = s.split()\n",
    "lemmatizer = stem.WordNetLemmatizer()\n",
    "for i in range(len(words)):\n",
    "    words[i] = lemmatizer.lemmatize(words[i],pos='v')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'against', 'm', 'themselves', \"needn't\", 'will', 'your', 'shouldn', 'at', \"mustn't\", \"shan't\", 'theirs', \"wasn't\", 'what', 'mightn', \"haven't\", 'are', 'as', 'so', 'their', \"won't\", \"hadn't\", 'such', 'haven', 'our', 'any', 'ours', 'nor', 're', \"wouldn't\", \"mightn't\", 'why', 'ain', 'all', 'll', 'very', 'them', 'most', 'if', 'more', 'because', 'y', 'were', \"you'll\", 'hadn', 'under', 'how', 'my', \"you'd\", 'now', 'these', 'here', 'shan', 'each', 'when', 'him', 'up', 'should', \"hasn't\", \"should've\", 'wouldn', 'himself', 'between', \"weren't\", 'doesn', 'herself', 'who', 'had', 'for', 'below', 'same', 'once', 'weren', \"it's\", 'didn', 'needn', 'a', 've', 'the', 'but', 'that', 'she', 'some', 'was', \"you've\", \"isn't\", 'yourselves', 'did', 'mustn', 'after', 'is', 'myself', 'ma', 'out', 'he', 'do', 'down', 'just', 'where', 'of', 'hasn', 'or', \"that'll\", 'itself', \"shouldn't\", 'i', 'own', 'be', 'does', 'until', 'have', 'ourselves', 'during', 'o', 'this', 'there', 'whom', 'me', 'over', 'they', 'only', 't', 'about', 'to', 'his', 'those', 'again', 'you', 'won', 'aren', 'don', 'am', 'been', 'with', 'hers', 'can', 'her', \"didn't\", 'couldn', 'an', 'it', 'through', 'then', \"don't\", \"doesn't\", 'while', \"you're\", 'doing', 'too', 'wasn', 'other', 'isn', \"she's\", 'has', 'which', 'd', 'being', 'few', 'yourself', 'and', \"aren't\", \"couldn't\", 'further', 'not', 's', 'its', 'than', 'both', 'into', 'by', 'on', 'off', 'before', 'in', 'yours', 'from', 'no', 'above', 'having', 'we'}\n"
     ]
    }
   ],
   "source": [
    "#Stop word removal\n",
    "#Show stopword list\n",
    "#We can add our own stop word by adding own stop word to that list\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-5e53255738cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'comment_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mDF\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mANNOTATION\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "def ANNOTATION(df):\n",
    "    length=df.shape[0]\n",
    "    for i in range(length):\n",
    "        soup = BeautifulSoup(df.loc[i,['comment_text']].values[0],\"lxml\")\n",
    "        [s.extract() for s in soup('script','iframe','html')] \n",
    "        df.loc[i,['comment_text']]=soup.get_text()\n",
    "    return df\n",
    "DF=ANNOTATION(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['explanation', 'edit', 'make', 'username', 'hardcore', 'metallica', 'fan', 'revert', 'werent', 'vandalisms', 'closure', 'gas', 'vote', 'new', 'york', 'dolls', 'fac', 'please', 'dont', 'remove', 'template', 'talk', 'page', 'since', 'im', 'retire']\n"
     ]
    }
   ],
   "source": [
    "#Stop word removal\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "meaningful_words = [w for w in words if not w in stops] \n",
    "print(meaningful_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Capital and lower count as different.\n",
    "def comment_to_words_1(comment):\n",
    "    lemmatizer = stem.WordNetLemmatizer()\n",
    "    comment = remove_number(comment)\n",
    "    comment = replace_contraction(comment)\n",
    "    comment = remove_symbols(comment)\n",
    "    comment = remove_punctuation(comment)\n",
    "    comment = re.sub(\"[^a-zA-Z]\", \" \", comment) \n",
    "    words = comment.split()\n",
    "    for i in range(len(words)):\n",
    "        words[i] = lemmatizer.lemmatize(words[i],pos='v')\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    # Join the words back into one string separated by space and return the result.\n",
    "    return( \" \".join( meaningful_words ))   \n",
    "\n",
    "#Capital and lower count as same and only include letters\n",
    "def comment_to_words_2(comment):\n",
    "    lemmatizer = stem.WordNetLemmatizer()\n",
    "    comment = comment.lower()\n",
    "    comment = replace_contraction(comment)\n",
    "    comment = remove_symbols(comment)\n",
    "    comment = remove_punctuation(comment)\n",
    "    comment = remove_number(comment)\n",
    "    comment = re.sub(\"[^a-zA-Z]\", \" \", comment) \n",
    "    words = comment.split()\n",
    "    for i in range(len(words)):\n",
    "        words[i] = lemmatizer.lemmatize(words[i],pos='v')\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    # Join the words back into one string separated by space and return the result.\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explanation edit make username hardcore metallica fan revert vandalisms closure gas vote new york dolls fac please remove template talk page since retire\n"
     ]
    }
   ],
   "source": [
    "print(comment_to_words_2(df_train[\"comment_text\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [02:03<00:00, 1295.36it/s]\n"
     ]
    }
   ],
   "source": [
    "#tqdm is the library to show the progress of the iteration. You can omit if you want\n",
    "from tqdm import tqdm\n",
    "clean_comment_train = []\n",
    "for i in tqdm(range(df_train.shape[0])):\n",
    "    clean_comment_train.append(comment_to_words_1(df_train[\"comment_text\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153164/153164 [01:48<00:00, 1408.80it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_comment_test = []\n",
    "for i in tqdm(range(df_test.shape[0])):\n",
    "    clean_comment_test.append(comment_to_words_1(df_test[\"comment_text\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#You can save as new csv file as preprocessing takes time\n",
    "df_train[\"comment_text\"] = clean_comment_train\n",
    "df_train.to_csv( 'clean_train_2.csv' )\n",
    "df_test[\"comment_text\"] = clean_comment_test\n",
    "df_test.to_csv( 'clean_test_2.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159571/159571 [01:29<00:00, 1781.39it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_comment_train = []\n",
    "for i in tqdm(range(df_train.shape[0])):\n",
    "    clean_comment_train.append(comment_to_words_2(df_train[\"comment_text\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 153164/153164 [01:21<00:00, 1880.31it/s]\n"
     ]
    }
   ],
   "source": [
    "clean_comment_test = []\n",
    "for i in tqdm(range(df_test.shape[0])):\n",
    "    clean_comment_test.append(comment_to_words_2(df_test[\"comment_text\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Without capital letter\n",
    "df_train[\"comment_text\"] = clean_comment_train\n",
    "df_train.to_csv( 'clean_train_wo_capital_2.csv' )\n",
    "df_test[\"comment_text\"] = clean_comment_test\n",
    "df_test.to_csv( 'clean_test_wo_capital_2.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
